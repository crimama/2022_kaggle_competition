{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0045eac-6550-4378-bba3-55e833181094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from glob import glob \n",
    "from tqdm import tqdm \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6cef98af-c450-40b5-8166-7dcb2a5e5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getcwd() == '/data/2022_kaggle_competition/Data':\n",
    "    pass\n",
    "else:\n",
    "    os.chdir('/data/2022_kaggle_competition/Data')\n",
    "    \n",
    "file_dirs = glob('*.csv')\n",
    "\n",
    "df = []\n",
    "for dir in file_dirs:\n",
    "  exec(f\"{dir.split('.')[0]}=pd.read_csv('{dir}')\")\n",
    "  df.append(dir.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ab8a4-3a94-442b-918f-c3a664abeca9",
   "metadata": {},
   "source": [
    "# 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e9ead3a-2878-47b8-b1ae-c33b3c3c2f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25968, 60, 13) (20768, 1)\n"
     ]
    }
   ],
   "source": [
    "#이상치 제거 \n",
    "def remove_out(data:pd.Series):\n",
    "    iqr_3 = np.percentile(data,75)\n",
    "    iqr_1 = np.percentile(data,25)\n",
    "    data.loc[data>iqr_3] = iqr_3 \n",
    "    data.loc[data<iqr_1] = iqr_1 \n",
    "    return data \n",
    "\n",
    "#스케일링 \n",
    "def minmax(data):\n",
    "    min_value  = np.min(data,axis=0)\n",
    "    max_value = np.max(data,axis=0)\n",
    "    return_value = (data-min_value)/(max_value-min_value)\n",
    "    scalied_value = {}\n",
    "    scalied_value['min'] = min_value \n",
    "    scalied_value['max'] = max_value \n",
    "    return return_value,scalied_value \n",
    "\n",
    "def preprocess(train):\n",
    "    x = train.drop(columns = ['sequence','subject','step'])\n",
    "    \n",
    "    columns = x.columns \n",
    "    for column in tqdm(columns):\n",
    "        data = x[column]\n",
    "        data = remove_out(data)\n",
    "        x[column] = data\n",
    "    \n",
    "    x,scalied_value = minmax(np.array(x))\n",
    "    \n",
    "    x = x.reshape(-1,60,13)\n",
    "    return x,scalied_value \n",
    "\n",
    "\n",
    "\n",
    "def make_label(train_labels):\n",
    "    labels = np.unique(train_labels['state'])\n",
    "    train_labels = np.array(train_labels.drop(columns=['sequence']))\n",
    "    return train_labels \n",
    "\n",
    "train_x,scalied_value = preprocess(train)\n",
    "labels = make_label(train_labels)\n",
    "\n",
    "print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c0fc3b3-9b75-443e-8d9b-27d67b365871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25968, 60, 13) (20768, 1)\n"
     ]
    }
   ],
   "source": [
    "#이상치 제거 \n",
    "def remove_out(data:pd.Series):\n",
    "    iqr_3 = np.percentile(data,75)\n",
    "    iqr_1 = np.percentile(data,25)\n",
    "    data.loc[data>iqr_3] = iqr_3 \n",
    "    data.loc[data<iqr_1] = iqr_1 \n",
    "    return data \n",
    "\n",
    "#스케일링 \n",
    "def minmax(data):\n",
    "    min_value  = np.min(data,axis=0)\n",
    "    max_value = np.max(data,axis=0)\n",
    "    return_value = (data-min_value)/(max_value-min_value)\n",
    "    scalied_value = {}\n",
    "    scalied_value['min'] = min_value \n",
    "    scalied_value['max'] = max_value \n",
    "    return return_value,scalied_value \n",
    "\n",
    "def preprocess(train):\n",
    "    x = train.drop(columns = ['sequence','subject','step'])\n",
    "    \n",
    "    columns = x.columns \n",
    "    for column in tqdm(columns):\n",
    "        data = x[column]\n",
    "        data = remove_out(data)\n",
    "        x[column] = data\n",
    "    \n",
    "    x,scalied_value = minmax(np.array(x))\n",
    "    \n",
    "    x = x.reshape(-1,60,13)\n",
    "    return x,scalied_value \n",
    "\n",
    "\n",
    "\n",
    "def make_label(train_labels):\n",
    "    labels = np.unique(train_labels['state'])\n",
    "    train_labels = np.array(train_labels.drop(columns=['sequence']))\n",
    "    return train_labels \n",
    "\n",
    "train_x,scalied_value = preprocess(train)\n",
    "labels = make_label(train_labels)\n",
    "\n",
    "print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b3908-58d4-4dcc-a2c3-649b1ba6736b",
   "metadata": {},
   "source": [
    "# shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63af016d-ad2c-43b6-b48f-739dd34335e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nums = np.arange(len(train_x))\n",
    "np.random.shuffle(nums)\n",
    "\n",
    "train_x = train_x[nums]\n",
    "labels = labels[nums]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef66731d-a583-470b-a27f-9d40d4952ba5",
   "metadata": {},
   "source": [
    "## Train-valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93d28d56-e939-43f1-a922-8674838bfd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(len(train_x)*0.1)\n",
    "train_df = train_x[:idx*8]\n",
    "valid_df = train_x[idx*8:idx*9]\n",
    "test_df = train_x[idx*9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af907138-3beb-43f2-bb5b-e9235ad9416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = labels[:idx*8]\n",
    "valid_y = labels[idx*8:idx*9]\n",
    "test_y = labels[idx*9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6155f0c-6263-4483-9d76-d09979353577",
   "metadata": {},
   "source": [
    "# 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fca910-a271-4f9f-ac65-9a27a8b50693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,Bidirectional,Conv2D\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0aad7e-e978-4d96-8c32-ec4e4b614ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_df.shape[1:]\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209243f1-cb37-4406-9675-96cb2e959f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_block(node,input_layer):\n",
    "  x = input_layer \n",
    "  x = Bidirectional(LSTM(node,return_sequences=True))(x)\n",
    "  x = layers.Normalization()(x)\n",
    "  return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18ccd99d-5462-4ce0-baea-66c6b9e89f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 60, 13)]          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 60, 256)          145408    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " normalization_3 (Normalizat  (None, 60, 256)          513       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 60, 64)           73984     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " normalization_4 (Normalizat  (None, 60, 64)           129       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 60, 4)            1072      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " normalization_5 (Normalizat  (None, 60, 4)            9         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 240)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 482       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221,597\n",
      "Trainable params: 220,946\n",
      "Non-trainable params: 651\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(input_shape)\n",
    "x = inputs\n",
    "x = encoding_block(128,x)\n",
    "x = encoding_block(32,x)\n",
    "x = encoding_block(2,x)\n",
    "x = layers.Flatten()(x)\n",
    "x = Dense(2,activation = 'softmax')(x)\n",
    "model = keras.Model(inputs,x)\n",
    "model.summary()\n",
    "model.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a7afb60-03b1-46d2-bdfb-1bf6e355bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6925 - accuracy: 0.5182 - val_loss: 0.6884 - val_accuracy: 0.5343\n",
      "Epoch 2/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6904 - accuracy: 0.5337 - val_loss: 0.6900 - val_accuracy: 0.5351\n",
      "Epoch 3/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6896 - accuracy: 0.5369 - val_loss: 0.6909 - val_accuracy: 0.5354\n",
      "Epoch 4/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6892 - accuracy: 0.5391 - val_loss: 0.6905 - val_accuracy: 0.5297\n",
      "Epoch 5/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6884 - accuracy: 0.5415 - val_loss: 0.6933 - val_accuracy: 0.5297\n",
      "Epoch 6/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6906 - accuracy: 0.5266 - val_loss: 0.6910 - val_accuracy: 0.5235\n",
      "Epoch 7/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6901 - accuracy: 0.5326 - val_loss: 0.6983 - val_accuracy: 0.5092\n",
      "Epoch 8/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6875 - accuracy: 0.5456 - val_loss: 0.6902 - val_accuracy: 0.5289\n",
      "Epoch 9/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6886 - accuracy: 0.5430 - val_loss: 0.6933 - val_accuracy: 0.5324\n",
      "Epoch 10/100\n",
      "1298/1298 [==============================] - 64s 49ms/step - loss: 0.6884 - accuracy: 0.5431 - val_loss: 0.6927 - val_accuracy: 0.5347\n",
      "Epoch 11/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6891 - accuracy: 0.5425 - val_loss: 0.6907 - val_accuracy: 0.5339\n",
      "Epoch 12/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6879 - accuracy: 0.5437 - val_loss: 0.6890 - val_accuracy: 0.5331\n",
      "Epoch 13/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6884 - accuracy: 0.5424 - val_loss: 0.6913 - val_accuracy: 0.5231\n",
      "Epoch 14/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6895 - accuracy: 0.5390 - val_loss: 0.6885 - val_accuracy: 0.5212\n",
      "Epoch 15/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6887 - accuracy: 0.5412 - val_loss: 0.6905 - val_accuracy: 0.5404\n",
      "Epoch 16/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6874 - accuracy: 0.5435 - val_loss: 0.6893 - val_accuracy: 0.5112\n",
      "Epoch 17/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6860 - accuracy: 0.5428 - val_loss: 0.6851 - val_accuracy: 0.5262\n",
      "Epoch 18/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6867 - accuracy: 0.5435 - val_loss: 0.6864 - val_accuracy: 0.5331\n",
      "Epoch 19/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6828 - accuracy: 0.5588 - val_loss: 0.6822 - val_accuracy: 0.5543\n",
      "Epoch 20/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6820 - accuracy: 0.5623 - val_loss: 0.6857 - val_accuracy: 0.5505\n",
      "Epoch 21/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6808 - accuracy: 0.5579 - val_loss: 0.6804 - val_accuracy: 0.5609\n",
      "Epoch 22/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6854 - accuracy: 0.5509 - val_loss: 0.6845 - val_accuracy: 0.5474\n",
      "Epoch 23/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6816 - accuracy: 0.5575 - val_loss: 0.6741 - val_accuracy: 0.5713\n",
      "Epoch 24/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6638 - accuracy: 0.5945 - val_loss: 0.6702 - val_accuracy: 0.5794\n",
      "Epoch 25/100\n",
      "1298/1298 [==============================] - 64s 49ms/step - loss: 0.6566 - accuracy: 0.6000 - val_loss: 0.6757 - val_accuracy: 0.5666\n",
      "Epoch 26/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.6546 - accuracy: 0.6046 - val_loss: 0.6359 - val_accuracy: 0.6387\n",
      "Epoch 27/100\n",
      "1298/1298 [==============================] - 64s 49ms/step - loss: 0.6236 - accuracy: 0.6483 - val_loss: 0.6158 - val_accuracy: 0.6587\n",
      "Epoch 28/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.6081 - accuracy: 0.6641 - val_loss: 0.6011 - val_accuracy: 0.6737\n",
      "Epoch 29/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.5880 - accuracy: 0.6864 - val_loss: 0.5901 - val_accuracy: 0.6784\n",
      "Epoch 30/100\n",
      "1298/1298 [==============================] - 64s 49ms/step - loss: 0.5709 - accuracy: 0.7006 - val_loss: 0.5692 - val_accuracy: 0.6911\n",
      "Epoch 31/100\n",
      "1298/1298 [==============================] - 64s 50ms/step - loss: 0.5555 - accuracy: 0.7117 - val_loss: 0.5720 - val_accuracy: 0.7069\n",
      "Epoch 32/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.5423 - accuracy: 0.7247 - val_loss: 0.5572 - val_accuracy: 0.7080\n",
      "Epoch 33/100\n",
      "1298/1298 [==============================] - 64s 49ms/step - loss: 0.5302 - accuracy: 0.7303 - val_loss: 0.5381 - val_accuracy: 0.7142\n",
      "Epoch 34/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.5184 - accuracy: 0.7403 - val_loss: 0.5363 - val_accuracy: 0.7230\n",
      "Epoch 35/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.5077 - accuracy: 0.7487 - val_loss: 0.5464 - val_accuracy: 0.7111\n",
      "Epoch 36/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.4975 - accuracy: 0.7567 - val_loss: 0.5452 - val_accuracy: 0.7149\n",
      "Epoch 37/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.4846 - accuracy: 0.7599 - val_loss: 0.5352 - val_accuracy: 0.7219\n",
      "Epoch 38/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.4704 - accuracy: 0.7716 - val_loss: 0.5328 - val_accuracy: 0.7227\n",
      "Epoch 39/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.4560 - accuracy: 0.7825 - val_loss: 0.5361 - val_accuracy: 0.7196\n",
      "Epoch 40/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.4516 - accuracy: 0.7799 - val_loss: 0.5494 - val_accuracy: 0.7207\n",
      "Epoch 41/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.4288 - accuracy: 0.7977 - val_loss: 0.5444 - val_accuracy: 0.7215\n",
      "Epoch 42/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.4082 - accuracy: 0.8066 - val_loss: 0.5933 - val_accuracy: 0.7192\n",
      "Epoch 43/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.3898 - accuracy: 0.8197 - val_loss: 0.5953 - val_accuracy: 0.7238\n",
      "Epoch 44/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.3702 - accuracy: 0.8320 - val_loss: 0.6125 - val_accuracy: 0.7061\n",
      "Epoch 45/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.3450 - accuracy: 0.8462 - val_loss: 0.6139 - val_accuracy: 0.7157\n",
      "Epoch 46/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.3192 - accuracy: 0.8596 - val_loss: 0.6483 - val_accuracy: 0.7153\n",
      "Epoch 47/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.2926 - accuracy: 0.8744 - val_loss: 0.7379 - val_accuracy: 0.7180\n",
      "Epoch 48/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.2675 - accuracy: 0.8850 - val_loss: 0.7262 - val_accuracy: 0.7107\n",
      "Epoch 49/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.2467 - accuracy: 0.8973 - val_loss: 0.7751 - val_accuracy: 0.7230\n",
      "Epoch 50/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.2086 - accuracy: 0.9129 - val_loss: 0.8418 - val_accuracy: 0.7161\n",
      "Epoch 51/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.1981 - accuracy: 0.9207 - val_loss: 0.8693 - val_accuracy: 0.7234\n",
      "Epoch 52/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.1585 - accuracy: 0.9388 - val_loss: 0.8857 - val_accuracy: 0.7042\n",
      "Epoch 53/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.1449 - accuracy: 0.9429 - val_loss: 1.0773 - val_accuracy: 0.7076\n",
      "Epoch 54/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.1214 - accuracy: 0.9535 - val_loss: 1.1529 - val_accuracy: 0.7211\n",
      "Epoch 55/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.1085 - accuracy: 0.9604 - val_loss: 1.1714 - val_accuracy: 0.6880\n",
      "Epoch 56/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.0925 - accuracy: 0.9662 - val_loss: 1.2583 - val_accuracy: 0.7103\n",
      "Epoch 57/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.0824 - accuracy: 0.9691 - val_loss: 1.2638 - val_accuracy: 0.7049\n",
      "Epoch 58/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0856 - accuracy: 0.9687 - val_loss: 1.2732 - val_accuracy: 0.6918\n",
      "Epoch 59/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0817 - accuracy: 0.9700 - val_loss: 1.3467 - val_accuracy: 0.7176\n",
      "Epoch 60/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0736 - accuracy: 0.9729 - val_loss: 1.3093 - val_accuracy: 0.7099\n",
      "Epoch 61/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0546 - accuracy: 0.9814 - val_loss: 1.4879 - val_accuracy: 0.7030\n",
      "Epoch 62/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 1.4757 - val_accuracy: 0.7080\n",
      "Epoch 63/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.0529 - accuracy: 0.9825 - val_loss: 1.5011 - val_accuracy: 0.7080\n",
      "Epoch 64/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.1157 - accuracy: 0.9632 - val_loss: 1.3618 - val_accuracy: 0.6992\n",
      "Epoch 65/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 1.5899 - val_accuracy: 0.6914\n",
      "Epoch 66/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0411 - accuracy: 0.9859 - val_loss: 1.5102 - val_accuracy: 0.7076\n",
      "Epoch 67/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0427 - accuracy: 0.9853 - val_loss: 1.6188 - val_accuracy: 0.7003\n",
      "Epoch 68/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0569 - accuracy: 0.9788 - val_loss: 1.5953 - val_accuracy: 0.7042\n",
      "Epoch 69/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0469 - accuracy: 0.9829 - val_loss: 1.5618 - val_accuracy: 0.7038\n",
      "Epoch 70/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0392 - accuracy: 0.9868 - val_loss: 1.6014 - val_accuracy: 0.7007\n",
      "Epoch 71/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.0436 - accuracy: 0.9849 - val_loss: 1.6446 - val_accuracy: 0.7030\n",
      "Epoch 72/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0446 - accuracy: 0.9846 - val_loss: 1.7320 - val_accuracy: 0.7119\n",
      "Epoch 73/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 1.6350 - val_accuracy: 0.6999\n",
      "Epoch 74/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.0519 - accuracy: 0.9821 - val_loss: 1.6643 - val_accuracy: 0.7030\n",
      "Epoch 75/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 1.6379 - val_accuracy: 0.6914\n",
      "Epoch 76/100\n",
      "1298/1298 [==============================] - 66s 51ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 1.7260 - val_accuracy: 0.6961\n",
      "Epoch 77/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 1.6792 - val_accuracy: 0.7034\n",
      "Epoch 78/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0409 - accuracy: 0.9857 - val_loss: 1.7394 - val_accuracy: 0.7038\n",
      "Epoch 79/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 1.7354 - val_accuracy: 0.7130\n",
      "Epoch 80/100\n",
      "1298/1298 [==============================] - 65s 50ms/step - loss: 0.0377 - accuracy: 0.9876 - val_loss: 1.7720 - val_accuracy: 0.7130\n",
      "Epoch 81/100\n",
      "1298/1298 [==============================] - 66s 50ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 1.6864 - val_accuracy: 0.7084\n",
      "Epoch 82/100\n",
      " 387/1298 [=======>......................] - ETA: 43s - loss: 0.0271 - accuracy: 0.9911"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1401\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1400\u001b[0m   data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m         epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m         step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m         _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m       callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py:1248\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1248\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1249\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1250\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\n\u001b[1;32m   1253\u001b[0m     original_spe)\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py:712\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m the read operation.\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 712\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py:678\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_variable_op\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 678\u001b[0m   \u001b[43mvariable_accessed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_and_set_handle\u001b[39m():\n\u001b[1;32m    681\u001b[0m     result \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mread_variable_op(\n\u001b[1;32m    682\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py:329\u001b[0m, in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    327\u001b[0m   ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39mwatch_variable(variable)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m variable\u001b[38;5;241m.\u001b[39mtrainable:\n\u001b[0;32m--> 329\u001b[0m   \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable_accessed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/tape.py:116\u001b[0m, in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m   variables \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mexperimental_local_results(variable)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m    117\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeVariableAccessed(var)\n\u001b[1;32m    118\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_VariableWatcherVariableAccessed(var)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_df,train_y,batch_size=16,validation_data=(valid_df,valid_y),epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619f157-9566-4d52-9a3a-85e2b8f5a9ec",
   "metadata": {},
   "source": [
    "# Test 데이터 추론 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72c2bfe8-f227-4af5-9e96-be83b6406b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>subject</th>\n",
       "      <th>step</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>sensor_09</th>\n",
       "      <th>sensor_10</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>sensor_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25968</td>\n",
       "      <td>684</td>\n",
       "      <td>0</td>\n",
       "      <td>2.427357</td>\n",
       "      <td>19.639706</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.466372</td>\n",
       "      <td>-1.289973</td>\n",
       "      <td>-4.207928</td>\n",
       "      <td>2.486339</td>\n",
       "      <td>-2.493893</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.123555</td>\n",
       "      <td>-1.673048</td>\n",
       "      <td>10.980453</td>\n",
       "      <td>0.419011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25968</td>\n",
       "      <td>684</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.950541</td>\n",
       "      <td>-21.747899</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.983186</td>\n",
       "      <td>-0.569053</td>\n",
       "      <td>1.845924</td>\n",
       "      <td>-3.887978</td>\n",
       "      <td>1.727481</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>0.395231</td>\n",
       "      <td>-0.882233</td>\n",
       "      <td>-1.871399</td>\n",
       "      <td>-0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25968</td>\n",
       "      <td>684</td>\n",
       "      <td>2</td>\n",
       "      <td>1.136012</td>\n",
       "      <td>-10.756303</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.016814</td>\n",
       "      <td>0.964157</td>\n",
       "      <td>2.454749</td>\n",
       "      <td>0.312386</td>\n",
       "      <td>1.154198</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1.114162</td>\n",
       "      <td>1.525273</td>\n",
       "      <td>-11.584362</td>\n",
       "      <td>0.139812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25968</td>\n",
       "      <td>684</td>\n",
       "      <td>3</td>\n",
       "      <td>0.806028</td>\n",
       "      <td>6.504202</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.179646</td>\n",
       "      <td>0.969221</td>\n",
       "      <td>-1.035153</td>\n",
       "      <td>-0.457195</td>\n",
       "      <td>0.254962</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>-0.588873</td>\n",
       "      <td>0.608761</td>\n",
       "      <td>-4.241770</td>\n",
       "      <td>-0.462916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25968</td>\n",
       "      <td>684</td>\n",
       "      <td>4</td>\n",
       "      <td>1.288253</td>\n",
       "      <td>5.552521</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.493805</td>\n",
       "      <td>-1.036124</td>\n",
       "      <td>-1.126402</td>\n",
       "      <td>2.008197</td>\n",
       "      <td>-0.730534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.899566</td>\n",
       "      <td>-1.259615</td>\n",
       "      <td>-0.472222</td>\n",
       "      <td>-0.121483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733075</th>\n",
       "      <td>38185</td>\n",
       "      <td>773</td>\n",
       "      <td>55</td>\n",
       "      <td>0.211747</td>\n",
       "      <td>2.005252</td>\n",
       "      <td>-1.33282</td>\n",
       "      <td>0.695575</td>\n",
       "      <td>-0.161327</td>\n",
       "      <td>-1.193717</td>\n",
       "      <td>0.421676</td>\n",
       "      <td>0.869466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.536850</td>\n",
       "      <td>0.388101</td>\n",
       "      <td>2.205761</td>\n",
       "      <td>-91.610827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733076</th>\n",
       "      <td>38185</td>\n",
       "      <td>773</td>\n",
       "      <td>56</td>\n",
       "      <td>-0.826121</td>\n",
       "      <td>-2.468487</td>\n",
       "      <td>-1.33282</td>\n",
       "      <td>0.381416</td>\n",
       "      <td>0.144745</td>\n",
       "      <td>1.060583</td>\n",
       "      <td>-0.765938</td>\n",
       "      <td>0.288550</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.956647</td>\n",
       "      <td>-0.032158</td>\n",
       "      <td>-1.794239</td>\n",
       "      <td>72.414749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733077</th>\n",
       "      <td>38185</td>\n",
       "      <td>773</td>\n",
       "      <td>57</td>\n",
       "      <td>0.755023</td>\n",
       "      <td>1.469538</td>\n",
       "      <td>-1.33282</td>\n",
       "      <td>-1.253097</td>\n",
       "      <td>-0.414802</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.907104</td>\n",
       "      <td>-1.556489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.341763</td>\n",
       "      <td>0.150273</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>-34.065644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733078</th>\n",
       "      <td>38185</td>\n",
       "      <td>773</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.187017</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>-1.33282</td>\n",
       "      <td>0.077876</td>\n",
       "      <td>1.323245</td>\n",
       "      <td>0.159312</td>\n",
       "      <td>-0.397996</td>\n",
       "      <td>0.306870</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.013728</td>\n",
       "      <td>-0.608616</td>\n",
       "      <td>0.317901</td>\n",
       "      <td>65.659420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733079</th>\n",
       "      <td>38185</td>\n",
       "      <td>773</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.414992</td>\n",
       "      <td>-2.858193</td>\n",
       "      <td>-1.33282</td>\n",
       "      <td>1.061062</td>\n",
       "      <td>-0.264150</td>\n",
       "      <td>-0.449514</td>\n",
       "      <td>-0.601093</td>\n",
       "      <td>1.621374</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.650289</td>\n",
       "      <td>-0.147107</td>\n",
       "      <td>-1.559671</td>\n",
       "      <td>57.189685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733080 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sequence  subject  step  sensor_00  sensor_01  sensor_02  sensor_03  \\\n",
       "0          25968      684     0   2.427357  19.639706    1.00000  -1.466372   \n",
       "1          25968      684     1  -4.950541 -21.747899    1.00000   0.983186   \n",
       "2          25968      684     2   1.136012 -10.756303    1.00000   1.016814   \n",
       "3          25968      684     3   0.806028   6.504202    1.00000  -0.179646   \n",
       "4          25968      684     4   1.288253   5.552521    1.00000  -0.493805   \n",
       "...          ...      ...   ...        ...        ...        ...        ...   \n",
       "733075     38185      773    55   0.211747   2.005252   -1.33282   0.695575   \n",
       "733076     38185      773    56  -0.826121  -2.468487   -1.33282   0.381416   \n",
       "733077     38185      773    57   0.755023   1.469538   -1.33282  -1.253097   \n",
       "733078     38185      773    58  -0.187017   0.714286   -1.33282   0.077876   \n",
       "733079     38185      773    59  -0.414992  -2.858193   -1.33282   1.061062   \n",
       "\n",
       "        sensor_04  sensor_05  sensor_06  sensor_07  sensor_08  sensor_09  \\\n",
       "0       -1.289973  -4.207928   2.486339  -2.493893        8.0  -1.123555   \n",
       "1       -0.569053   1.845924  -3.887978   1.727481       -2.9   0.395231   \n",
       "2        0.964157   2.454749   0.312386   1.154198       -5.6   1.114162   \n",
       "3        0.969221  -1.035153  -0.457195   0.254962       -2.7  -0.588873   \n",
       "4       -1.036124  -1.126402   2.008197  -0.730534        0.0   0.899566   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "733075  -0.161327  -1.193717   0.421676   0.869466        0.0  -1.536850   \n",
       "733076   0.144745   1.060583  -0.765938   0.288550        0.2  -1.956647   \n",
       "733077  -0.414802   0.007479   0.907104  -1.556489        0.4   4.341763   \n",
       "733078   1.323245   0.159312  -0.397996   0.306870        0.1  -1.013728   \n",
       "733079  -0.264150  -0.449514  -0.601093   1.621374       -1.0  -3.650289   \n",
       "\n",
       "        sensor_10  sensor_11  sensor_12  \n",
       "0       -1.673048  10.980453   0.419011  \n",
       "1       -0.882233  -1.871399  -0.008525  \n",
       "2        1.525273 -11.584362   0.139812  \n",
       "3        0.608761  -4.241770  -0.462916  \n",
       "4       -1.259615  -0.472222  -0.121483  \n",
       "...           ...        ...        ...  \n",
       "733075   0.388101   2.205761 -91.610827  \n",
       "733076  -0.032158  -1.794239  72.414749  \n",
       "733077   0.150273   0.641975 -34.065644  \n",
       "733078  -0.608616   0.317901  65.659420  \n",
       "733079  -0.147107  -1.559671  57.189685  \n",
       "\n",
       "[733080 rows x 16 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "239f8acb-b789-4cb2-988d-f80ab616c216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 38.48it/s]\n"
     ]
    }
   ],
   "source": [
    "def test_minmax(test,scalied_value):\n",
    "    min_value = scalied_value['min']\n",
    "    max_value = scalied_value['max']\n",
    "    return_value = (test-min_value)/(max_value-min_value)\n",
    "    return return_value \n",
    "\n",
    "def test_preprocess(test,scalied_value):\n",
    "    x = test.drop(columns = ['sequence','subject','step'])\n",
    "    \n",
    "    columns = x.columns \n",
    "    for column in tqdm(columns):\n",
    "        data = x[column]\n",
    "        data = remove_out(data)\n",
    "        x[column] = data\n",
    "    x = test_minmax(np.array(x),scalied_value)\n",
    "    x = x.reshape(-1,60,13)\n",
    "    return x \n",
    "test = test_preprocess(test,scalied_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce785f-5b95-4d22-a3f1-55ee73b8664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = model.predict(test)\n",
    "predicted = np.argmax(y_,axis=1)\n",
    "submission['state'] = predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cbd7a398-f66d-4ab5-a34d-4e1b6d62c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
